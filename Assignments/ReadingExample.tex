\documentclass[a4paper]{exam}
\printanswers
\usepackage[margin=1in]{geometry}

\title{Example Reading Summary: Lodge, McGraw, and Stroh (1990)}
\date{}

\begin{document}

\vspace{-4em}
\maketitle
\vspace{-4em}

\section{Purpose}\label{purpose}

Each week, about 3--4 readings are assigned that provide empirical examples of the week's theme or review articles summarizing a relevant body of literature. In order to prepare for class discussions, students should expect to prepare notes akin to this example for \textit{every} text.

\section{Lodge, McGraw, and Stroh (1990)}\label{overview}

\subsection{What is the research question?}

Lodge et al. are interested in how citizens form opinions toward political candidates and the degrees to which information about candidates affects overall evaluations and voting decisions. They ask three research questions (p.43): (1) do citizens engage in memory-based (MB) or online (OL) processing of candidate information? (2) are online evaluations subject to \textit{ordering} or \textit{importance} dynamics such that some information is accumulated into overall evaluations more than other information? and (3) is the type of processing used by citizens moderated by (i.e., affected by) their political sophistication/knowledge?

\subsection{What is the theory? Is it clearly argued and reasonable?}

Lodge et al. are interested in a long-running debate how citizens form evaluations of political candidates. A long-standing theory is that citizens are ``cold rational'' memory-based processors who weigh likes and dislikes about candidates in order to form an evaluation and a vote choice (p.41). Lodge et al. (1989) introduced a rival ``online'' processing theory that is ``impression-driven'' (p.42). The differences between the theories or models is that MB models involve the storage of information in long-term memory, the retrieval of those memories at a later date, and the formation of an overall candidate evaluation. The online model, by contrast, does not require the encoding of candidate-relevant information into long-term memory. Instead a ``judgement operator'' is activated (p.42) that summarizes encountered information ``on the fly'' into an overall evaluation and only this overall evaluation is stored in memory.

The two rival theories are empirically distinguishable by the correlation (or lack thereof) between information retrieved from memory and the voter's overall evaluation of a candidate. If memory-based processing is at work, then these should be closely linked. If online processing is at work, they may be unrelated. A key moderator of whether one type of processing is used as opposed to other is motivation during the original encounter with the information (bottom p.42).

\subsection{To which literature does the article contribute?}

This piece contributes to the literature on candidate evaluation and voter decision-making. It does not cite very much of this literature, however, so it is sometimes unclear exactly who they are speaking to. There is an implicit assumption that existing literature widely adopts an MB approach to candidate evaluation but doesn't point to very many specific articles making that claim.

The paper also speaks to the authors' own earlier work. For example, it extends Lodge et al. (1989) in two ways. First, the OL model implies an equal/additive influence of any given piece of information (pp.43--44) that may not be true, so the current paper tests that. Second, the type of processing used by a voter may be moderated by their knowledge or sophistication (p.44) and that is tested here, as well. In the latter case, the authors expect that ``sophisticates'' (those with high political knowledge) are more likely to engage in OL processing.

\subsection{What are the hypotheses or expectations? Do these derive clearly from theory? Are they falsifiable?}

The expectations are somewhat clear but not terribly explicit. The expectation around differences in processing by levels of political knowledge is clearly stated (p.44) but the precise expectations surrounding issue order or importance are more vague (p.43) and seems more exploratory but suggests (top p.44) that more important issues may be more influential on evaluations.

These are not derived from a broader theory, but are reasonably argued. There are weaknesses in the argumentation. Given the exploratory nature of the issue order and importance tests, they do not seem clearly falsifiable. The sophistication hypothesis is falsifiable because there may be no differences between those with high and low levels of political knowledge, falsifying this expectation.

\subsection{What is the method of analysis? How are data collected? How appropriate are the method and data?}

The study is quantitative in nature, using a relatively small sample size (n=219) gathered from interviews conducted on Long Island, New York in 1988. Interviews were conducted face-to-face by trained student interviewers (p.45). Participants were shown 32 policy stances of a fictitious (but supposedly real) Republican Party political candidate (bottom p.45) and to state whether they agreed or disagreed with each position (this is used to create the ``online evaluation'' measure; p.47). The order of these issues was randomized (p.46). After reading the statements, participants completed a ``distractor'' activity (to flush working memory), and were then asked to recall the policy positions and to indicate whether each of 32 statements was by the politician (16 were, 16 were not). They then provided an overall evaluation of the candidate (this is the key outcome measure; p.47) and provided various answers to policy opinion and political knowledge questions. Measures of position recall were used to operationalize MB processing.

The analysis is then a simple OLS regression of evaluations on each of the measures: online evaluation (based on the agree/disagree ratings), memory of the candidate's issue stances, party identification, ideology, and respondent sex.

The method seems intriguing, but has problems. (Thomas: I will leave you to decide what the issues are in this study.)

\subsection{What are the results? Do they support the proposed theory?}

The results show a strong correlation between early evaluations of agreement with the candidate's policy positions and their final evaluation of the candidate. Memory of the candidate seems to have little influence on evaluations (Table 1; p.49).

In terms of the moderation of the relationships by political knowledge, there is some evidence that this is true. While the correlation between the online tally and summary evaluation is large and positive for ``sophisticates'' and ``nonsophisticates'' the correlation is larger for sophisticates (consistent with expectations).

In terms of issue order, there are some interesting results. Early information seems to be particularly influential on evaluations, but ``nonsophisticates'' rely more on later information (a ``recency effect'') and ``sophisticates'' rely on earlier information (a ``primacy effect'') but also seem to use all information more.

In terms of issue importance, the results are murky. All information seems to matter, regardless of whether the issue is important or unimportant to the respondent, though ``very important'' issues seem to be more influential.

Overall, the evidence seems to be consistent with the author's expectations.

\subsection{Discussion Questions}

\begin{enumerate}
\item Lodge et al. setup OL and MB models as being theoretical rivals. Isn't it possible that voters use both approaches at some point during a political campaign?
\item The experiment itself seems fairly contrived and unrealistic. Participants were only shown policy stances but little other information and they only thought about one candidate. How could this study be improved to make it more realistic? What would we gain from a more realistic study? And what challenges would greater realism introduce?
\end{enumerate}


\end{document}
